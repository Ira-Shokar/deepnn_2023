<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2021-02-04">
  <title>Hardware Ecosystem</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//css/theme/black.css" id="theme">
  <link rel="stylesheet" href="../assets/css/talks.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'https://unpkg.com/reveal.js@^4//css/print/pdf.css' : 'https://unpkg.com/reveal.js@^4//css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="https://unpkg.com/reveal.js@^4//lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    TeX: {
         extensions: ["color.js"]
      }
    });
  </script>
  <script src="../assets/js/figure-animate.js"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Hardware Ecosystem</h1>
  <p class="author" style="text-align:center"><a href="http://niclane.org/">Nic Lane</a></p>
  <p class="date" style="text-align:center"><time>2021-02-04</time></p>
  <p class="venue" style="text-align:center">Computer Laboratory, William Gates Building</p>
</section>

<section class="slide level2">

<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
</section>
<section id="deepnn" class="slide level2">
<h2>DeepNN</h2>
</section>
<section id="plan-for-the-day" class="slide level2">
<h2>Plan for the Day</h2>
<ul>
<li><strong>Introduction</strong>
<ul>
<li><strong>How did we get here?</strong></li>
</ul></li>
<li>Hardware Foundation</li>
<li>Parallelism Leveraging</li>
<li>Data Movement and Bandwidth Pressures</li>
<li>Closing messages</li>
</ul>
</section>
<section id="hardware-at-deep-learnings-birth" class="slide level2">
<h2>Hardware at Deep Learning's birth</h2>
<table>
<tr>
<td>
<center>
<h2>
New York Times (1958)
</h2>
</center>
</td>
<td>
<center>
<h2>
Eniac, 1950s SoTA Hardware
</h2>
</center>
</td>
</tr>
<tr>
<td>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/NYT_core.png" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/hardware/Eniac.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</section>
<section id="how-did-we-get-here-deep-learning-requires-peta-flops" class="slide level2">
<h2>How did we get here? Deep Learning requires <em>peta</em> FLOPS</h2>
<center>
0.01 PFLOP (left) = <span class="math inline">\(10^{13}\)</span> FLOPS (right)
</center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_MACs.png" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/FLOPS.png" width="" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<p>Credits: Our World in Data (<a href="https://ourworldindata.org/technological-progress" class="uri">https://ourworldindata.org/technological-progress</a>)</p>
</section>
<section id="plan-for-the-day-1" class="slide level2">
<h2>Plan for the Day</h2>
<ul>
<li>Introduction</li>
<li><strong>Hardware Foundation</strong>
<ul>
<li><strong>Internal organisation of processors</strong></li>
<li><strong>A typical organisation of a DL system</strong></li>
<li><strong>Two pillars: Data Movement &amp; Parallelism</strong></li>
</ul></li>
<li>Parallelism Leveraging</li>
<li>Data Movement and Bandwidth Pressures</li>
<li>Closing messages</li>
</ul>
</section>
<section id="internal-organisation-of-processors" class="slide level2">
<h2>Internal Organisation of Processors</h2>
<table>
<tr>
<td>
<center>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/hardware/AMDprocessor.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
<td>
<center>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/hardware/GPU.jpg" width="90%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
<td>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/TPU_out.png" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
</tr>
</table>
</section>
<section id="central-processing-unit-cpu" class="slide level2">
<h2>Central Processing Unit (CPU)</h2>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_CPU.png" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<ul>
<li>General-purpose processor (in use since mid-1950s)</li>
<li>CPU is composed of cores, each of which consists of several threads.</li>
<li>Example high-end performance:
<ul>
<li>AMD Ryzen 9 5950X</li>
<li>No. Cores:    <strong>16</strong></li>
<li>No. Threads:   <strong>32</strong></li>
<li>Clock speed:   <strong>3.4GHz</strong>, boost up to <strong>4.9GHz</strong></li>
<li>L2 cache:     <strong>8 MB</strong></li>
<li>L3 cache:     <strong>64 MB</strong></li>
</ul></li>
</ul>
<p>:::</p>
</section>
<section id="graphics-processing-unit" class="slide level2 cell code" data-scrolled="false" data-slideshow="{&quot;slide_type&quot;:&quot;-&quot;}">
<h2>Graphics Processing Unit</h2>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_GPU.png" width="35%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<ul>
<li>Parallelism-exploiting Accelerator</li>
<li>Originally used for graphics processing (in use since 1970s)</li>
<li>GPU is composed of a large number of threads organised into blocks (cores)</li>
<li>Example high-end performance:
<ul>
<li>NVIDIA GEFORCE RTX 3090</li>
<li>No. Threads:   <strong>10496</strong></li>
<li>Clock speed:   <strong>1.4GHz</strong>, boost up to <strong>1.7GHz</strong></li>
<li>L2 cache:     <strong>24 GB</strong></li>
</ul></li>
</ul>
</section>
<div class="cell code" data-scrolled="false" data-slideshow="{&quot;slide_type&quot;:&quot;-&quot;}">
<section id="graphics-processing-unit-1" class="slide level2">
<h2>Graphics Processing Unit</h2>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_GPU.png" width="35%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<ul>
<li>Register (per thread)</li>
<li>An automatic variable in kernel function * Low latency, high bandwidth * Local Memory (per thread) * Variable in a kernel but can not be fitted in register</li>
<li>Shared Memory (between thread blocks)</li>
<li>All threads faster than local and global memory * Use for inter-thread communication</li>
<li>physically shared with L1 cache * Constant memory * Per Device Read-only memory * Texture Memory * Per SM, read-only cache, optimized for 2D spatial locality</li>
<li>Global Memory
<p></li>
</ul>
</section>
<section id="a-typical-organisation-of-a-dl-system" class="slide level2">
<h2>A typical organisation of a DL system</h2>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_hardwareOrg.png" width="52.5%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<ul>
<li>Processors</li>
<li>CPU sits at the centre of the system</li>
<li><u><strong>Accelerators</strong></u><br />
</li>
<li>GPUs, TPUs, Eyeriss, other specialised</li>
<li>Specialised hardware can be designed with exploiting <u><strong>parallelism</strong></u> in mind<br />
</li>
<li><u><strong>Memory hierarchy</strong></u></li>
<li>Caches - smallest and fastest * Random Access Memory (RAM) - largest and slowest</li>
<li>Disk / SSD - storage<br />
</li>
<li>Stores the dataset; in crisis it supplements RAM up to Swap</li>
<li><u><strong>Bandwidth</strong></u> can be serious a bottleneck</li>
<li>System, memory, and I/O buses</li>
<li>Closer to processor - faster<br />
</li>
<li>Designed to transport fixed-size data chunks<br />
</li>
<li>Word size is a key system parameter 4 bytes (32 bit) or 8 bytes (64 bit) </pp><br />
</li>
<li>Auxiliary hardware</li>
<li>Mouse, keyboard, display<br />

<p></li>
</ul>
</section>
<section id="data-movement-parallelism" class="slide level2">
<h2>Data Movement &amp; Parallelism</h2>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_hardwareOrg.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</section>
<section id="memory-and-bandwidth-memory-hierarchy" class="slide level2">
<h2>Memory and bandwidth: memory hierarchy</h2>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_hierarchy2.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</section>
<section id="memory-and-bandwidth-data-movement" class="slide level2">
<h2>Memory and bandwidth: data movement</h2>
<ul>
<li>Energy and latency are commensurate</li>
<li>Accessing RAM is 3 to 4 <u>orders of magnitude</u> slower than executing MAC</li>
</ul>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/latencynumbers.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</section>
<section id="processor-comparison-based-on-memory-and-bandwidth" class="slide level2">
<h2>Processor comparison based on memory and bandwidth</h2>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_memoryInversion.png" width="45%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<ul>
<li>CPU has faster I/O bus than GPU, but it has lower bandwidth than GPU. <pp>CPU can fetch small pieces of data very fast, GPU fetches them slower but in bulk.</pp> * GPU has more lower-level memory than CPU. <pp>Even though each individual thread and thread block have less memory than the</pp> <pp>CPU threads and cores do, there are just so much more threads in the GPU that</pp><br />
<pp><strong>taken as a whole</strong> they have much more lower-level memory.</pp> <pp>This is memory inversion.</pp>
<p></li>
</ul>
</section>
<section id="the-case-for-parallelism---moores-law-is-slowing-down" class="slide level2">
<h2>The case for parallelism - Moore's law is slowing down</h2>
<ul>
<li><em>Moore's law fuelled the prosperity of the past 50 years.</em></li>
</ul>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/Moores_Law.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
<p>Credits: Our World in Data (<a href="https://ourworldindata.org/technological-progress" class="uri">https://ourworldindata.org/technological-progress</a>)</p>
</section>
<section id="plan-for-the-day-2" class="slide level2">
<h2>Plan for the Day</h2>
<ul>
<li>Introduction</li>
<li>Hardware Foundation</li>
<li><strong>Parallelism Leveraging</strong>
<ul>
<li><strong>Parallelism in Deep Learning</strong></li>
<li><strong>Leveraging Deep Learning parallelism</strong></li>
</ul></li>
<li>Data Movement and Bandwidth Pressures</li>
<li>Closing messages</li>
</ul>
</section>
<section id="the-case-for-parallelism---moores-law-is-slowing-down-1" class="slide level2">
<h2>The case for parallelism - Moore’s law is slowing down</h2>
<ul>
<li><em>As it slows, programmers and hardware designers are searching for alternative drivers of performance growth.</em></li>
</ul>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/Moores_Law2.png" width="65%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
<p>Credits: Karl Rupp (<a href="https://github.com/karlrupp/microprocessor-trend-data" class="uri">https://github.com/karlrupp/microprocessor-trend-data</a>)</p>
</section>
<section id="processor-comparison-based-on-parallelism" class="slide level2">
<h2>Processor comparison based on parallelism</h2>
</section>
</div>
<p>::: {.cell .code execution_count=“3” scrolled=“false”}</p>
<div class="output stream stdout">
<pre><code>CPU matrix multiplication
CPU took 0.0005156993865966797 seconds
GPU matrix multiplication
GPU took 0.0002989768981933594 seconds</code></pre>
</div>
<section id="plan-for-the-day-3" class="slide level2">
<h2>Plan for the Day</h2>
<ul>
<li>Introduction</li>
<li>Hardware Foundation</li>
<li><strong>Parallelism Leveraging</strong>
<ul>
<li><strong>Parallelism in Deep Learning</strong></li>
<li><strong>Leveraging Deep Learning parallelism</strong></li>
</ul></li>
<li>Data Movement and Bandwidth Pressures</li>
<li>Closing messages</li>
</ul>
</section>
<section id="parallelism-in-deep-learning-training" class="slide level2">
<h2>Parallelism in Deep Learning training</h2>
<ul>
<li>Minibatch model update:</li>
</ul>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/Picture1.png" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
<ul>
<li>where <span class="math inline">\(\theta^{s}_{l,i}\)</span> is an <span class="math inline">\(i\)</span>'s parameter at layer <span class="math inline">\(l\)</span> value at step <span class="math inline">\(s\)</span> of the training process; <span class="math inline">\(r\)</span> is the learning rate; <span class="math inline">\(B\)</span> is the batch size; and <span class="math inline">\(g^{s}_{l,i,b}\)</span> is the <span class="math inline">\(s\)</span>-th training step gradient coming from <span class="math inline">\(b\)</span>-th training example for parameter update of <span class="math inline">\(i\)</span>-th parameter at layer <span class="math inline">\(l\)</span>.</li>
</ul>
</section>
<section id="dl-parallelism-parallelize-backprop-through-an-example" class="slide level2">
<h2>DL parallelism: parallelize backprop through an example</h2>
<ul>
<li>The matrix multiplications in the forward and backward passes can be parallelized:</li>
</ul>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/Picture2.png" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
<ul>
<li>Fast inference is unthinkable without parallel matrix multiplication.</li>
<li>Frequent synchronization is needed - at each layer the parallel threads need to sync up.</li>
</ul>
</section>
<section id="dl-parallelism-parallelize-gradient-sample-computation" class="slide level2">
<h2>DL parallelism: parallelize gradient sample computation</h2>
<ul>
<li>Gradients for individual training examples can be computed in parallel:</li>
</ul>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/Picture3.png" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
<ul>
<li>Synchronization is needed only at the point where we sum the individual gradients across the batch.</li>
</ul>
</section>
<section id="dl-parallelism-parallelize-update-iterations" class="slide level2">
<h2>DL parallelism: parallelize update iterations</h2>
<ul>
<li>Gradient updates from separate batches can be computed in parallel:</li>
</ul>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/Picture4.png" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
<ul>
<li>Imagine computing <span class="math inline">\(N\)</span> batches at the same time in parallel:
<ul>
<li>We can see this as using <span class="math inline">\(N-1\)</span> outdated gradient when making update based on the second batch.</li>
<li>We can see this as using <span class="math inline">\(N\)</span> gradient estimates in place of the usual <span class="math inline">\(1\)</span> that SGD is based on.</li>
</ul></li>
</ul>
</section>
<section id="dl-parallelism-parallelize-the-training-of-multiple-models" class="slide level2">
<h2>DL parallelism: parallelize the training of multiple models</h2>
<ul>
<li>In the course of solving a given DL problem one would often train competing models because of:
<ul>
<li>The choice of hyperparameters such as architecture, initialization, dropout and learning rates, regularization, ...</li>
<li>The desire to build a model ensemble.</li>
</ul></li>
</ul>
<center>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/hardware/hyperparameter.jpg" width="90%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
<ul>
<li>The models are independent of each other and thus can be computed in parallel.</li>
</ul>
</section>
<section id="leveraging-deep-learning-parallelism" class="slide level2">
<h2>Leveraging Deep Learning parallelism</h2>
<ul>
<li>CPUs, GPUs, multi-GPU, and multi-machine each offer unique opportunities to leverage the four sources of parallelism.</li>
</ul>
<p>XXXX</p>
<p>XXXX</p>
<p>XXXX</p>
<p>XXXX</p>
</section>
<section id="cpu-training" class="slide level2">
<h2>CPU training</h2>
<p>The most a CPU can do for this setup is to:</p>
<ul>
<li>Run through the batches <em>sequentially</em></li>
<li>Run through the model <em>sequentially</em></li>
<li>Run through the batch <em>sequentially</em></li>
<li>Potentially, <em>parallelize</em> each layer computation between its cores
<ul>
<li>Best case scenario: individual cores can tackle separate nodes / channels as these are independent of each other</li>
</ul></li>
<li><em>Parallelize</em> matrix multiplication
<ul>
<li>Best case scenario: Matrix multiplication is split between separate cores and threads. The degree of parallelism is, however, negligent.</li>
</ul></li>
</ul>
</section>
<section id="cpu-training-1" class="slide level2">
<h2>CPU training</h2>
<p>Consequently:</p>
<ul>
<li>Overpowered CPU threads are scrambling to juggle the many nodes / channels they need to compute.</li>
<li>The CPU is slowed down considerably by the fact that it needs to access its own L3 cache many more times than the GPU would, due to its lower memory access bandwidth.</li>
</ul>
<div class="output stream stdout">
<pre><code>CPU training code
CPU training of the above-defined model short example of how long it takes</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Epoch 1, iter 469, loss 1.980: : 469it [00:02, 181.77it/s]
Epoch 2, iter 469, loss 0.932: : 469it [00:02, 182.58it/s]</code></pre>
</div>
<div class="output stream stdout">
<pre><code>CPU took 5.22 seconds</code></pre>
</div>
<div class="output stream stderr">

</div>
</section>
<section id="gpu-training" class="slide level2">
<h2>GPU training</h2>
<p>The GPU, on the other hand, can:</p>
<ul>
<li>Run through the batches <em>sequentially</em></li>
<li>Run through the model <em>sequentially</em>
<ul>
<li>The model and the batch size just fit once in the memory of the GPU we chose.</li>
</ul></li>
<li>In the best case scenario run through the training examples in a batch in <em>parallel</em>
<ul>
<li>For most GPUs the computation is, however, <em>sequential</em> if their memory is not big enough to hold the entire batch of training examples.</li>
</ul></li>
<li><em>Parallelize</em> each layer computation between its cores
<ul>
<li>Groups of several cores are assigned to separate network layers / channels. Cores in the group need not be physically close to each other.</li>
</ul></li>
<li><em>Parallelize</em> matrix multiplication
<ul>
<li>The matrix multiplication needed to compute a given node / channel is split between the threads in the group that was assigned to it. Each thread computes separate sector of the input.</li>
</ul></li>
</ul>
</section>
<section id="gpu-training-1" class="slide level2">
<h2>GPU training</h2>
<p>Consequently:</p>
<ul>
<li>GPU cores are engaged at all times as they sequentially push through the training examples all at the same time.</li>
<li>All threads need to sync-up at the end of each layer computation so that their outputs can become the inputs to the next layer.</li>
</ul>
<div class="output stream stdout">
<pre><code>GPU training
GPU training of the same example as in CPU</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Epoch 1, iter 118, iter loss 0.786: : 118it [00:02, 52.62it/s]
Epoch 2, iter 118, iter loss 0.760: : 118it [00:02, 57.48it/s]</code></pre>
</div>
<div class="output stream stdout">
<pre><code>GPU took 4.37 seconds</code></pre>
</div>
<div class="output stream stderr">

</div>
</section>
<section id="gpu-parallelism-matrix-multiplication-example" class="slide level2">
<h2>GPU parallelism: matrix multiplication example</h2>
<table>
<tr>
<td>
<center>
<h2>
GPU
</h2>
</center>
</td>
<td>
<center>
<h2>
Naive implementation
</h2>
</center>
</td>
<td>
<center>
<h2>
Shared memory implementation
</h2>
</center>
</td>
</tr>
<tr>
<td>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_GPU.png" width="45%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
<td>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_matmulVOsharedMemory.png" width="45%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
<td>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_matmul.png" width="45%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
</tr>
<tr>
<td>
<center>
<pp>
<h6>
12 thread blocks, each with 16 threads.
</h6>
</pp>
</center>
</td>
<td>
<center>
<pp>
<h6>
Each <strong>thread</strong> reads one row of A, one <br>column of B and returns one element of C.
</h6>
</pp>
</center>
</td>
<td>
<center>
<pp>
<h6>
Each <strong>thread <u>block</u></strong> is computing <br>one square sub-matrix.
</h6>
</pp>
</center>
</td>
</tr>
</table>
</section>
<section id="gpu-parallelism-matrix-multiplication-example-1" class="slide level2">
<h2>GPU parallelism: matrix multiplication example</h2>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/fig7.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</section>
<section id="multi-gpu-training" class="slide level2">
<h2>Multi-GPU training</h2>
<p>With multiple GPUs we can choose one of the following:</p>
<ul>
<li><em>Distribute</em> the training examples of a batch between GPUs
<ul>
<li>When individual GPUs can not hold the whole batch in the memory, this can be distributed between multiple cards.</li>
<li>The computation has to sync-up for each Batch-Norm.</li>
</ul></li>
<li><em>Parallelize</em> the model computation
<ul>
<li>Separate layers or groups of layers are handled by separate GPUs.</li>
<li>Computation syncs between pairs of GPU cards - as the one's outputs are the other's inputs.</li>
<li>This creates a flow-through system that will keep all GPUs busy at all times during the training.</li>
<li>Batch is processed sequentially, all GPUs sync up after each batch - either dead time or outdated gradients.</li>
</ul></li>
<li><em>Parallelize</em> the gradient computation
<ul>
<li>Each GPU can be given its own batch if we accept outdated model in gradient computations.</li>
</ul></li>
</ul>
</section>
<section id="multi-gpu-training-1" class="slide level2">
<h2>Multi-GPU training</h2>
<div class="output stream stdout">
<pre><code>multi-GPU training
GPU training of the same example as in single GPU but with two GPUs</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Epoch 1, iter 59, iter loss 0.745: : 59it [00:02, 21.24it/s]
Epoch 2, iter 59, iter loss 0.736: : 59it [00:01, 31.70it/s]</code></pre>
</div>
<div class="output stream stdout">
<pre><code>2 GPUs took 4.72 seconds</code></pre>
</div>
<div class="output stream stderr">

</div>
</section>
<section id="multi-machine-training" class="slide level2">
<h2>Multi-Machine training</h2>
<p>In principle the same options as in multi-GPU:</p>
<ul>
<li><em>Distribute</em> the training examples of a batch between GPUs
<ul>
<li>This is rarely if ever needed on the scale of multi-Machine</li>
</ul></li>
<li><em>Parallelize</em> the model computation
<ul>
<li>Same principles as in multi-GPU.</li>
</ul></li>
<li><em>Parallelize</em> the gradient computation
<ul>
<li>Same principles as in multi-GPU.</li>
</ul></li>
</ul>
<p>In practice we would either take advantage of the latter two. In extreme examples one might do a combination of multiple options.</p>
</section>
<section id="parallelism-summary-model-and-data-parallelism" class="slide level2">
<h2>Parallelism summary: model and data parallelism</h2>
<table>
<tr>
<td>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/dataParallelism.png" width="35%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/modelParallelism.png" width="35%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</section>
<section id="parallelism-bottlenecks-synchronization-communication" class="slide level2">
<h2>Parallelism bottlenecks: Synchronization &amp; Communication</h2>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/distributed_bottlenecks4.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<ul>
<li>DL-training hardware needs to synchronize and communicate very frequently</li>
<li>Model nodes are heavily interconnected at each model layer.</li>
<li>Data nodes are interconnected by batch-norm-style layers</li>
<li>Data nodes are interconnected at gradient computation</li>
<li>This communication occurs between</li>
<li>Threads in a core (CPU and GPU)</li>
<li>Cores within a chip</li>
<li>Pieces of hardware <em>example: SLI bridge is a connector and a protocol for such a communication</em></li>
</ul>
</section>
<section id="bottlenecks-beyond-parallelism" class="slide level2">
<h2>Bottlenecks beyond parallelism</h2>
<ul>
<li>DL training and inference do not take place solely on the accelerator.
<ul>
<li>The accelerator accelerates the gradient computations and updates.</li>
<li>The CPU will still need to be loading the data (model, train set) and saving the model (checkpointing).</li>
</ul></li>
<li>The accelerator starves if it waits idly for its inputs due for example to slow CPU, I/O buses, or storage interface (SATA, SSD, NVMe).</li>
</ul>
<div class="output stream stdout">
<pre><code>starving GPUs
show in-code what starving GPU looks like
Using only 1 worker for the dataloader, the time the GPU takes increases.</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Epoch 1, iter 938, iter loss 0.699: : 938it [00:04, 214.02it/s]
Epoch 2, iter 938, iter loss 0.619: : 938it [00:04, 208.96it/s]</code></pre>
</div>
<div class="output stream stdout">
<pre><code>GPU took 8.92 seconds</code></pre>
</div>
</section>
<section id="plan-for-the-day-4" class="slide level2">
<h2>Plan for the Day</h2>
<ul>
<li>Introduction</li>
<li>Hardware Foundation</li>
<li>Parallelism Leveraging</li>
<li><strong>Data Movement and Bandwidth Pressures</strong>
<ul>
<li><strong>Deep Learning working set</strong></li>
<li><strong>Mapping Deep Learning onto hardware</strong></li>
<li><strong>Addressing memory pressure</strong></li>
</ul></li>
<li>Closing messages</li>
</ul>
</section>
<section id="deep-learning-resource-characterisation" class="slide level2">
<h2>Deep Learning resource characterisation</h2>
<div class="output stream stdout">
<pre><code>profiling demo
in-house DL training resource profiling code &amp; output - based on the above model and training loop
Operation                              OPS      
-------------------------------------  -------  
LeNet/Conv2d[conv1]/onnx::Conv         89856    
LeNet/ReLU[relu1]/onnx::Relu           6912     
LeNet/MaxPool2d[pool1]/onnx::MaxPool   2592     
LeNet/Conv2d[conv2]/onnx::Conv         154624   
LeNet/ReLU[relu2]/onnx::Relu           2048     
LeNet/MaxPool2d[pool2]/onnx::MaxPool   768      
LeNet/Linear[fc1]/onnx::Gemm           30720    
LeNet/ReLU[relu3]/onnx::Relu           240      
LeNet/Linear[fc2]/onnx::Gemm           7200     
LeNet/ReLU[relu4]/onnx::Relu           120      
LeNet/Linear[fc3]/onnx::Gemm           600      
LeNet/ReLU[relu5]/onnx::Relu           20       
------------------------------------   ------   
Input size: (1, 1, 28, 28)
295,700 FLOPs or approx. 0.00 GFLOPs</code></pre>
</div>
</section>
<section id="deep-learning-working-set" class="slide level2">
<h2>Deep Learning working set</h2>
<ul>
<li>Working set - a collection of all elements needed for executing a given DL layer
<ul>
<li>Input and output activations</li>
<li>Parameters (weights &amp; biases)</li>
</ul></li>
</ul>
<div class="output stream stdout">
<pre><code>working set profiling</code></pre>
</div>
</section>
<section id="working-set-requirement-exceeding-ram" class="slide level2">
<h2>Working Set requirement exceeding RAM</h2>
<div class="output stream stdout">
<pre><code>exceeding RAM+Swap demo
exceeding working set experiment - see the latency spike over a couple of bytes of working set
Using 128 hidden nodes took 2.42 seconds,        training for 1000 epochs would take ~2423.7449169158936s
Using 256 hidden nodes took 2.31 seconds,        training for 1000 epochs would take ~2311.570882797241s
Using 512 hidden nodes took 2.38 seconds,        training for 1000 epochs would take ~2383.8846683502197s
Using 1024 hidden nodes took 2.56 seconds,        training for 1000 epochs would take ~2559.4213008880615s
Using 2048 hidden nodes took 3.10 seconds,        training for 1000 epochs would take ~3098.113536834717s
Using 4096 hidden nodes took 7.20 seconds,        training for 1000 epochs would take ~7196.521997451782s
Using 6144 hidden nodes took 13.21 seconds,        training for 1000 epochs would take ~13207.558155059814s</code></pre>
</div>
</section>
<section id="working-set-requirement-exceeding-ram-swap" class="slide level2">
<h2>Working Set requirement exceeding RAM + Swap</h2>
<div class="output stream stdout">
<pre><code>OOM - massive images
show in-code how this can hapen - say massive images; maybe show error message
Loading too many images at once causes errors.</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Epoch 1, iter 10, iter loss 0.596: : 10it [00:03,  2.78it/s]
Epoch 2, iter 2, iter loss 0.592: : 2it [00:01,  1.69it/s]</code></pre>
</div>
</section>
<section id="mapping-deep-models-to-hardware-systolic-arrays" class="slide level2">
<h2>Mapping Deep Models to hardware: Systolic Arrays</h2>
<table>
<tr>
<td>
<center>
<h2>
Core principle
</h2>
</center>
</td>
<td>
<center>
<h2>
Systolic system matrix multiplication
</h2>
</center>
</td>
</tr>
<tr>
<td>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/basic_systolic_system.png" width="45%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</td>
<td>
<center>
<video width="45%" height="" controls preload="none">
<source src="../slides/diagrams/hardware/systolic_array.mp4" type="video/mp4"/>
</video>
</center>
</td>
</tr>
</table>
</section>
<section id="mapping-deep-models-to-hardware-weight-input-and-output-stationarity" class="slide level2">
<h2>Mapping Deep Models to hardware: weight, input, and output stationarity</h2>
</section>
<section id="weight-stationary-design" class="slide level2">
<h2>Weight stationary design</h2>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/weight_stationary.png" width="45%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</section>
<section id="input-stationary-design" class="slide level2">
<h2>Input stationary design</h2>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/input_stationary.png" width="45%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</section>
<section id="output-stationary-design" class="slide level2">
<h2>Output stationary design</h2>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/output_stationary.png" width="45%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</section>
<section id="systolic-array-example-weight-stationary-google-tensor-processing-unit-tpu" class="slide level2">
<h2>Systolic array example: weight stationary Google Tensor Processing Unit (TPU)</h2>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/provisional_TPU3.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</section>
<section id="plan-for-the-day-5" class="slide level2">
<h2>Plan for the Day</h2>
<ul>
<li>Introduction</li>
<li>Hardware Foundation</li>
<li>Parallelism Leveraging</li>
<li>Data Movement and Bandwidth Pressures</li>
<li><strong>Closing messages</strong>
<ul>
<li><strong>Deep Learning stack</strong></li>
<li><strong>Deep Learning and accelerator co-design</strong></li>
<li><strong>The Hardware and the Software Lottery</strong></li>
</ul></li>
</ul>
</section>
<section id="deep-learning-stack" class="slide level2">
<h2>Deep Learning stack</h2>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/TVM_stack2.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</section>
<section id="beyond-hardware-methods" class="slide level2">
<h2>Beyond hardware methods</h2>
<ul>
<li>Sparsity leveraging
<ul>
<li>Sparsity-inducing compression</li>
<li>Sparsity leveraging hardware</li>
</ul></li>
<li>Numerical representation
<ul>
<li>Low precision</li>
<li>bfloat16</li>
<li>Quantization</li>
</ul></li>
<li>Low-level implementations
<ul>
<li>GEMM</li>
<li>cuDNN</li>
</ul></li>
</ul>
</section>
<section id="deep-learning-and-accelerator-co-design" class="slide level2">
<h2>Deep Learning and accelerator co-design</h2>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/codesign.png" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</section>
<section id="alexnet-how-gpu-memory-defined-its-architecture" class="slide level2">
<h2>AlexNet: how GPU memory defined its architecture</h2>
<ul>
<li>Alex Krizhevsky used two GTX 580 GPUs, each with 3GB of memory.</li>
<li>Theoretical AlexNet (without mid-way split) working set profiling:</li>
</ul>
<div class="output stream stdout">
<pre><code>profile AlexNet layers - show memory requirements
per-layer profiling of AlexNet - connects to the preceding slide</code></pre>
</div>
</section>
<section id="the-actual-alexnet-architecture" class="slide level2">
<h2>The actual AlexNet architecture</h2>
<p>AlexNet's architecture had to be split down the middle to accommodate the 3GB limit per unit in its two GPUs.</p>
<center>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/AlexNet.png" width="90%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</center>
</section>
<section id="beyond-hardware-methods-1" class="slide level2">
<h2>Beyond hardware methods</h2>
<ul>
<li>Sparsity leveraging
<ul>
<li>Sparsity-inducing compression</li>
<li>Sparsity leveraging hardware</li>
</ul></li>
<li>Numerical representation
<ul>
<li>Low precision</li>
<li>bfloat16</li>
<li>Quantization</li>
</ul></li>
<li>Low-level implementations
<ul>
<li>GEMM</li>
<li>cuDNN</li>
</ul></li>
</ul>
</section>
<section id="the-hardware-and-the-software-lotteries" class="slide level2">
<h2>The Hardware and the Software Lotteries</h2>
<center>
<strong><i>The software and hardware lottery describes the success of a software or a piece of hardware resulting not from its universal superiority, but, rather, from its fit to the broader hardware and software ecosystem.</i></strong>
</center>
<table>
<tr>
<td>
<center>
<h2>
Eniac (1950s)
</h2>
</center>
</td>
<td>
<center>
<h2>
All-optical NN (2019)
</h2>
</center>
</td>
</tr>
<tr>
<td>
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/hardware/Eniac.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td>
<div class="centered" style="">
<img class="" src="../slides/diagrams/hardware/futureDL.png" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</section>
<section id="summary-of-the-day" class="slide level2">
<h2>Summary of the Day</h2>
<ul>
<li>Introduction</li>
<li>Hardware Foundation</li>
<li>Parallelism Leveraging</li>
<li>Data Movement and Bandwidth Pressures</li>
<li>Closing messages</li>
</ul>
</section>
<section>
<section id="thank-you-for-your-attention" class="title-slide slide level1">
<h1>Thank you for your attention!</h1>

</section>
<section id="deep-learning-resource-characterisation-1" class="slide level2">
<h2>Deep Learning resource characterisation</h2>
</section></section>
    </div>
  </div>

  <script src="https://unpkg.com/reveal.js@^4//lib/js/head.min.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        // Transition style
        transition: 'None', // none/fade/slide/convex/concave/zoom
        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: 'https://unpkg.com/reveal.js@^4//lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'https://unpkg.com/reveal.js@^4//plugin/zoom-js/zoom.js', async: true },
          { src: 'https://unpkg.com/reveal.js@^4//plugin/math/math.js', async: true },
          { src: 'https://unpkg.com/reveal.js@^4//plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
