---
title: "Introduction"
venue: "Computer Laboratory, William Gates Building, 15 J. J. Thomson Avenue"
abstract: "<p>This lecture will give the background to what deep neural networks are, how they fit into the wider context of the field and why they are succesful.</p>"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: 
  twitter: 
  gscholar: 
  orcid: 
date: 2021-01-19
published: 2021-01-19
time: "14:00"
week: 1
session: 1
layout: lecture
categories:
- notes
---



<p>Related publications and links will appear here.</p>
<ol type="1">
<li>Data (many data, many classes)</li>
<li>Hardware</li>
<li>SGD</li>
<li>Autograd</li>
</ol>
<p>Domains</p>
<ol type="1">
<li>Perception and Representation</li>
<li>Speech</li>
<li>Vision</li>
<li>Language</li>
</ol>
<p>Bringing it together: Unsupervised pre-training, initialisation and RELU. Leading to a Zoo of methods.</p>
<p>Yann LeCun and Alfredo Canzianiâ€™s course on deep learning <a href="https://atcold.github.io/pytorch-Deep-Learning/" class="uri">https://atcold.github.io/pytorch-Deep-Learning/</a></p>

