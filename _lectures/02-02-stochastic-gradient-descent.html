---
title: "Optimization and Stochastic Gradient Descent"
venue: "Zoom"
abstract: "<p>This lecture will cover stochastic gradient descent.</p>"
author:
- given: Ferenc
  family: Husz√°r
  url: https://www.inference.vc/about/
  institute: 
  twitter: 
  gscholar: 
  orcid: 
date: 2021-02-02
published: 2021-02-02
time: "14:00"
week: 2
session: 2
youtube: "GDyD8KwSfvk"
layout: lecture
categories:
- notes
---



<p>No Free Lunch for Optimization: <a href="https://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf" class="uri">https://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf</a> <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-12767-1_5" class="uri">https://link.springer.com/chapter/10.1007%2F978-3-030-12767-1_5</a> Survey of Optimization methods for DeepNNs: <a href="https://arxiv.org/abs/2007.01547" class="uri">https://arxiv.org/abs/2007.01547</a></p>
<p>Related publications and links will appear here.</p>
<ul>
<li>SGD (why it works, high variance estimator etc)</li>
<li>Adam</li>
<li>RMS PropMixed mode</li>
</ul>

